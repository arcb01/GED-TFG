{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18877da6-7bff-4734-bbe5-6eb67a074511",
   "metadata": {},
   "source": [
    "# Multilabel classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7a7e20-6834-4f4d-bffd-171d6bff98f8",
   "metadata": {},
   "source": [
    "Model that classifies if an image is flawed (BLR, FRM or clear)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfa07d25-767a-497b-a249-f9d633a234f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.13.1+cu117\n",
      "Torchvision Version:  0.14.1+cu117\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function \n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import copy\n",
    "import io\n",
    "import cv2\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686ff188-d956-44f5-a6a5-a3a4a80d6806",
   "metadata": {},
   "source": [
    "**Load images data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91956686-0457-47c1-b551-d541a818486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../data/vw_mc_dataset.json', encoding='UTF-8') as m_json_file:\n",
    "    data = json.load(m_json_file)\n",
    "    mc_train_data = np.array(data[\"train\"], dtype=object)\n",
    "    mc_val_data = np.array(data[\"val\"], dtype=object)\n",
    "    mc_test_data = np.array(data[\"test\"], dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada87a0d-5a2a-4ec0-8209-f0f21bf27f7a",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e585d6d-8e90-4bc2-abd8-c48efb656e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, imgs_list, transform=None):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "        self.imgs_list = imgs_list\n",
    "        self.transform = transform\n",
    "        \n",
    "    def get_labels(self):\n",
    "        return np.where(self.imgs_list[:, 1::] == 1)[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "         # VizWiz dataset case\n",
    "        img_name = os.path.join(self.root_dir, self.imgs_list[idx][0])\n",
    "    \n",
    "        labels = self.imgs_list[idx][1::] # [x, y, z]  \n",
    "        label = int(np.where(labels == 1)[0][0]) # idx\n",
    "        \n",
    "        image = Image.open(img_name)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa5cbfd-e767-4aab-8628-d119b64b60ae",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eff22f46-780d-4d77-809a-f34191bb4f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs, save_path):\n",
    "    \"\"\"\n",
    "    Train the model\n",
    "    \"\"\"\n",
    "    \n",
    "    since = time.time()\n",
    "\n",
    "    acc_history = {\"train\": [], \"val\": []}\n",
    "    losses = {\"train\": [], \"val\": []}\n",
    "\n",
    "    # we will keep a copy of the best weights so far according to validation accuracy\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    outputs = model(inputs)\n",
    "                    loss = loss_fn(outputs.float(), labels)\n",
    "                    losses[phase].append(loss.cpu().detach().numpy())\n",
    "                    preds = torch.argmax(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            acc_history[phase].append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    #model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    \n",
    "    return model, acc_history, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cea85417-9f5e-4793-9baf-386032cf0bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNeXt(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (1): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
      "          (4): GELU(approximate='none')\n",
      "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
      "      )\n",
      "      (1): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
      "          (4): GELU(approximate='none')\n",
      "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0058823529411764705, mode=row)\n",
      "      )\n",
      "      (2): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=96, out_features=384, bias=True)\n",
      "          (4): GELU(approximate='none')\n",
      "          (5): Linear(in_features=384, out_features=96, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.011764705882352941, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
      "      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
      "          (4): GELU(approximate='none')\n",
      "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.017647058823529415, mode=row)\n",
      "      )\n",
      "      (1): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
      "          (4): GELU(approximate='none')\n",
      "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.023529411764705882, mode=row)\n",
      "      )\n",
      "      (2): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=192, out_features=768, bias=True)\n",
      "          (4): GELU(approximate='none')\n",
      "          (5): Linear(in_features=768, out_features=192, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.029411764705882353, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
      "      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (5): Sequential(\n",
      "      (0): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (4): GELU(approximate='none')\n",
      "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.03529411764705883, mode=row)\n",
      "      )\n",
      "      (1): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (4): GELU(approximate='none')\n",
      "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0411764705882353, mode=row)\n",
      "      )\n",
      "      (2): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (4): GELU(approximate='none')\n",
      "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.047058823529411764, mode=row)\n",
      "      )\n",
      "      (3): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (4): GELU(approximate='none')\n",
      "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.052941176470588235, mode=row)\n",
      "      )\n",
      "      (4): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (4): GELU(approximate='none')\n",
      "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.058823529411764705, mode=row)\n",
      "      )\n",
      "      (5): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (4): GELU(approximate='none')\n",
      "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.06470588235294118, mode=row)\n",
      "      )\n",
      "      (6): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (4): GELU(approximate='none')\n",
      "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.07058823529411766, mode=row)\n",
      "      )\n",
      "      (7): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (4): GELU(approximate='none')\n",
      "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.07647058823529412, mode=row)\n",
      "      )\n",
      "      (8): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=384, out_features=1536, bias=True)\n",
      "          (4): GELU(approximate='none')\n",
      "          (5): Linear(in_features=1536, out_features=384, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.0823529411764706, mode=row)\n",
      "      )\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
      "      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
      "    )\n",
      "    (7): Sequential(\n",
      "      (0): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate='none')\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.08823529411764706, mode=row)\n",
      "      )\n",
      "      (1): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate='none')\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.09411764705882353, mode=row)\n",
      "      )\n",
      "      (2): CNBlock(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
      "          (1): Permute()\n",
      "          (2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (3): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (4): GELU(approximate='none')\n",
      "          (5): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (6): Permute()\n",
      "        )\n",
      "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "  (classifier): Sequential(\n",
      "    (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    (2): Linear(in_features=768, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "def initialize_model(num_classes, model_name):\n",
    "    \"\"\"\n",
    "    Initialize blur model for binary classifaction\n",
    "    \"\"\"\n",
    "    \n",
    "    if str(model_name) == \"vgg16\" or str(model_name) == \"convnext\":\n",
    "        \n",
    "        if str(model_name) == \"vgg16\":\n",
    "            model = models.vgg16(weights='IMAGENET1K_V1')\n",
    "        else:\n",
    "            model = models.convnext_tiny(weights='IMAGENET1K_V1')\n",
    "                                         \n",
    "        num_ftrs = model.classifier[-1].in_features\n",
    "        model.classifier[-1] = nn.Linear(num_ftrs, num_classes)\n",
    "                                         \n",
    "    elif str(model_name) == \"resnet\":\n",
    "        model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "        model.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "    input_size = 224\n",
    "        \n",
    "    return model, input_size\n",
    "\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 3\n",
    "\n",
    "# Initialize the model\n",
    "model_name = \"convnext\"\n",
    "model, input_size = initialize_model(num_classes, model_name)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47cc18ce-5a58-4ccf-a82a-abf8c12ea91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ce_weights(data):\n",
    "    \n",
    "    class_samples = []\n",
    "    \n",
    "    for nc in [1,2,3]:\n",
    "        n_samples_c = data[np.where(data[:, nc] == 1)].shape[0]\n",
    "        class_samples.append(n_samples_c)\n",
    "\n",
    "    total_train_samples = sum(class_samples)\n",
    "    class_weights = [total_train_samples / (len(class_samples) * samples) for samples in class_samples]\n",
    "    class_weights = torch.FloatTensor(class_weights)\n",
    "    \n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57ef03b7-6bbf-4dee-b793-485a1c9495e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send the model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Weighted Cross entropy loss \n",
    "class_weights = calculate_ce_weights(np.array(mc_train_data, dtype=object))\n",
    "class_weights = torch.FloatTensor(class_weights).cuda()\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40465f6c-26ae-41b6-8811-ad37d57df09d",
   "metadata": {},
   "source": [
    "**Model params**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e67ba30-3214-4611-9b9e-65226df8730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = {\"lr\" : 2.5672e-5,\n",
    "     \"batch_size\" : 128,\n",
    "     \"num_epochs\" : 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd16e612-9a8b-4a82-a082-e569c24bc2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 5\n",
    "lr = hp[\"lr\"]\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148f987c-e7bd-4fc3-a4d9-42f42b6fd5a5",
   "metadata": {},
   "source": [
    "**Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9aa8f49-171d-4fcf-9d1d-7e59d45baba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform_normalize_values(simple_transforms, loader):\n",
    "    \n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    for images, _ in loader:\n",
    "        batch_samples = images.size(0) \n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "\n",
    "    mean /= len(loader.dataset)\n",
    "    std /= len(loader.dataset)\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "424ba579-bc19-4dd8-ae6e-481d1283fbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/media/arnau/SSD/VizWiz/models/multiclass/train/'\n",
    "val_dir = '/media/arnau/SSD/VizWiz/models/multiclass/val/'\n",
    "test_dir = '/media/arnau/SSD/VizWiz/models/multiclass/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f4e646f-046e-4475-9349-a2304b0151e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_path = f'../outputs/norms_MC.pkl'\n",
    "input_size = (224,224)\n",
    "\n",
    "if not os.path.exists(norm_path):\n",
    "\n",
    "    trnfsm = transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.ToTensor()])\n",
    "\n",
    "    train_dataset = ImageDataset(train_dir, mc_train_data, trnfsm)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=25, num_workers=0,\n",
    "                        shuffle=True)\n",
    "\n",
    "    train_mean, train_std = get_transform_normalize_values(trnfsm, train_loader)\n",
    "\n",
    "    train_normalize = transforms.Normalize(mean=train_mean, std=train_std)\n",
    "\n",
    "    with open(norm_path, 'wb') as f:\n",
    "        pickle.dump(train_normalize, f)\n",
    "\n",
    "else:\n",
    "    with open(norm_path, 'rb') as f:\n",
    "        train_normalize = pickle.load(f)\n",
    "    \n",
    "# Set transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.RandomCrop((int(input_size[0] * 0.5), \n",
    "                               int(input_size[1] * 0.5))),\n",
    "        transforms.GaussianBlur(kernel_size=9, sigma=(0.1, 2.0)),\n",
    "        transforms.ToTensor(),\n",
    "        train_normalize\n",
    "\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        train_normalize\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4a81a2-06ff-42d9-9aa0-846dfd1122d0",
   "metadata": {},
   "source": [
    "[source](https://github.com/ufoym/imbalanced-dataset-sampler/blob/master/torchsampler/imbalanced.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4907de5f-e20f-46e2-bf6b-50b768312e0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ImageDataset.__init__() got an unexpected keyword argument 'multiclass'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m ImageDataset(train_dir, mc_train_data, data_transforms[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      5\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m ImageDataset(val_dir, mc_val_data, data_transforms[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 6\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mImageDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmc_test_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_transforms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mmulticlass\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, \n\u001b[1;32m     10\u001b[0m                           num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m                           sampler\u001b[38;5;241m=\u001b[39mImbalancedDatasetSampler(train_dataset))\n\u001b[1;32m     13\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     14\u001b[0m                         num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     15\u001b[0m                           sampler\u001b[38;5;241m=\u001b[39mImbalancedDatasetSampler(val_dataset))\n",
      "\u001b[0;31mTypeError\u001b[0m: ImageDataset.__init__() got an unexpected keyword argument 'multiclass'"
     ]
    }
   ],
   "source": [
    "from torchsampler import ImbalancedDatasetSampler\n",
    "# Balance data giving corresponding weights to each class\n",
    "\n",
    "train_dataset = ImageDataset(train_dir, mc_train_data, data_transforms[\"train\"])\n",
    "val_dataset = ImageDataset(val_dir, mc_val_data, data_transforms[\"val\"])\n",
    "test_dataset = ImageDataset(test_dir, mc_test_data, data_transforms[\"val\"], \n",
    "                           multiclass=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, \n",
    "                          num_workers=0, pin_memory=True,\n",
    "                          sampler=ImbalancedDatasetSampler(train_dataset))\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,\n",
    "                        num_workers=0, pin_memory=True,\n",
    "                          sampler=ImbalancedDatasetSampler(val_dataset))\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, \n",
    "                         num_workers=0, pin_memory=True,\n",
    "                          sampler=ImbalancedDatasetSampler(test_dataset))\n",
    "\n",
    "dataloaders_dict = {\"train\": train_loader, \"val\": val_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f8960c-3470-4234-ba0a-b1ea02e681fa",
   "metadata": {},
   "source": [
    "**Model trainning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5fa7b1-89ba-4562-97fd-15d55d30e75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = f'../outputs/best_MC_{model_name}.pth'\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    # Train and evaluate\n",
    "    model, hist, losses = train_model(model, dataloaders_dict, loss_fn, optimizer, \n",
    "                                      num_epochs=num_epochs, save_path=save_path)\n",
    "    \n",
    "    # plot the losses and accuracies\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "    ax1.set_title(\"Loss\")\n",
    "    ax1.plot(losses[\"train\"], label=\"training loss\")\n",
    "    ax1.plot(losses[\"val\"], label=\"validation loss\")\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.set_title(\"Accuracy\")\n",
    "    ax2.plot([x.cpu().numpy() for x in hist[\"train\"]],label=\"training accuracy\")\n",
    "    ax2.plot([x.cpu().numpy() for x in hist[\"val\"]],label=\"val accuracy\")\n",
    "    ax2.set_ylim([0, 1])\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba446e8c-87e8-4d65-88ad-a1a6c02ce7d1",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e54ddc-9c43-489c-b5e6-8118c52d6aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "num_params = count_parameters(model)\n",
    "\n",
    "print(f\"Number of trainable parameters in the model: {num_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb1ae39-7f3e-4212-9fe3-2d7b484f489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_aoc_roc_curve(y_true, y_pred):\n",
    "    # Calculate AUC-ROC score and ROC curve using sklearn\n",
    "    auc_roc = roc_auc_score(y_true, y_pred, multi_class='ovr')\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred, multi_class='ovr')\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.plot(fpr, tpr, label='AUC = {:.2f}'.format(auc_roc))\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_confusion_matrix(cm, classes):\n",
    "    \"\"\"\n",
    "    This function plots the confusion matrix.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2\n",
    "    for i, j in np.ndindex(cm.shape):\n",
    "        plt.text(j, i, cm[i, j], ha=\"center\", va=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def evaluate(model, loss_fn, test_loader, device):\n",
    "    \"\"\"\n",
    "    Evaluate the model on the test set\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs.float(), targets)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        #predicted = torch.round(torch.sigmoid(outputs))\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += torch.sum(predicted == targets.data)\n",
    "        y_true += targets.cpu().numpy().tolist()\n",
    "        y_pred += predicted.cpu().detach().numpy().tolist()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = correct / total\n",
    "    test_f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    test_precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    test_recall = recall_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "    print(f\"Test F1 Score: {test_f1 * 100:.2f}%\")\n",
    "    print(f\"Test Precision: {test_precision * 100:.2f}%\")\n",
    "    print(f\"Test Recall: {test_recall * 100:.2f}%\")\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    return y_true, y_pred, cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97390999-7d9a-425d-85a6-445449e8ae78",
   "metadata": {},
   "source": [
    "**Results on test set**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587a6f15-b185-4ce8-b933-db01b6d6244f",
   "metadata": {},
   "source": [
    "**NOTE**: Thanks to previous preprocessing, test sat does not contain images from val set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26059752-a584-4e11-b2bf-ffb2a5c58283",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(save_path))\n",
    "\n",
    "class_labels = ['Clear', 'BLR', 'FRM']\n",
    "\n",
    "yt, yp, cm = evaluate(model, loss_fn, test_loader, device)\n",
    "\n",
    "#plot_aoc_roc_curve(yt, yp)\n",
    "plot_confusion_matrix(cm, classes=class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6477e5-f973-499a-8614-ab294a906586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(i):\n",
    "    \"\"\"\n",
    "    Model outputs 1 if the image is blurred otherwise 0\n",
    "    \"\"\"\n",
    "    \n",
    "    img = Image.open(i)\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)), \n",
    "        transforms.ToTensor(),        \n",
    "    ])\n",
    "\n",
    "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    #predicted = torch.round(torch.sigmoid(output))\n",
    "    pred = predicted.cpu().detach().numpy()[0]\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab31a7a-8cfb-40e8-97f0-9a8aa927b95c",
   "metadata": {},
   "source": [
    "**Inference visualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4957ca-4d64-42e1-81c1-49f6024b7051",
   "metadata": {},
   "source": [
    "Visualization of how the model performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af79e85-c2a9-497b-850b-83c40ec32a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_random_imgs = random.choices(mc_test_data, k=5)\n",
    "labels_names = {0 : \"Clear\", 1 : \"BLR\", 2 : \"FRM\"}\n",
    "\n",
    "for i, data in enumerate(ten_random_imgs):\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    img_name = data[0]\n",
    "    label = np.where(data[1::] == 1)[0][0]\n",
    "    img = test_dir + img_name\n",
    "    model_pred = inference(img)\n",
    "    model_pred = labels_names[model_pred]\n",
    "    print(f\"Model: {model_pred}\")\n",
    "    true_label = labels_names[label]\n",
    "    print(f\"True: {true_label}\")\n",
    "    img = cv2.cvtColor(cv2.imread(img), cv2.COLOR_BGR2RGB)\n",
    "    img = (img.astype(np.float32) / np.max(img) * 255).astype(np.uint8)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
