{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json, nltk\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from json import JSONEncoder\n",
    "import numpy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = \"val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdir = '/media/arnau/PEN/TFG/data_assesing/'\n",
    "source = f'/media/arnau/PEN/TFG/{split}/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(wdir):\n",
    "    \n",
    "    # load vqa annotations\n",
    "    vqa_annot = {'train': {}, 'val': {}, 'test': {}}\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        with open(wdir + 'annotations/vqa_annotations/{}.json'.format(split), encoding=\"utf8\") as file:\n",
    "            annot = json.load(file)\n",
    "            for entry in annot:\n",
    "                temp = {'question': entry['question']} \n",
    "                if split != 'test':\n",
    "                    temp['answerable'] = float(entry['answerable'])\n",
    "                vqa_annot[split][entry['image']] = temp\n",
    "                \n",
    "    THRESHOLD = 2\n",
    "    # load quality annotations\n",
    "    quality_annot = {'train': {}, 'val': {}, 'test': {}}\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        with open(wdir + 'annotations/quality_annotations/{}.json'.format(split)) as file:\n",
    "            annot = json.load(file)\n",
    "            for entry in annot:\n",
    "                temp = {} \n",
    "                if split != 'test':\n",
    "                    flaws = entry['flaws']\n",
    "                    #print(flaws.keys())\n",
    "                    temp['flaws'] = np.array(list(flaws.values())) >= THRESHOLD\n",
    "                    temp['recognizable'] = float(1 - (entry['unrecognizable'] >= THRESHOLD))\n",
    "                quality_annot[split][entry['image']] = temp\n",
    "                \n",
    "    merged_annot = {'train': {}, 'val': {}, 'test': {}}\n",
    "    for split in ['train', 'val']:\n",
    "        vqa_split, quality_split = vqa_annot[split], quality_annot[split]\n",
    "        for fname in vqa_split:\n",
    "            if quality_split.get(fname):\n",
    "                merged_annot[split][fname] = {**vqa_split[fname], **quality_split[fname]}\n",
    "                \n",
    "    return merged_annot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dict_keys(['FRM', 'BLR', 'DRK', 'BRT', 'OBS', 'OTH', 'NON', 'ROT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicc = load_data(wdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyArrayEncoder(JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, numpy.ndarray):\n",
    "            return obj.tolist()\n",
    "        return JSONEncoder.default(self, obj)\n",
    "    \n",
    "with open(f\"../../data/final_{split}.json\", \"w\") as outf:\n",
    "    data = json.dump(dicc, outf, cls=NumpyArrayEncoder) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
