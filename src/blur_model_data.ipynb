{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8573ae68-b392-4d41-bc10-8ee7d37a51d6",
   "metadata": {},
   "source": [
    "# Preparing a blur dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e79dd8d-406f-4198-9414-5d97748c4529",
   "metadata": {},
   "source": [
    "## VizWiz dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847362aa-5b85-4ff5-9c48-efd29068ff1c",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13475e0-11c4-4b45-aac9-cea6f219aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy  as np\n",
    "import cv2\n",
    "import random\n",
    "import json\n",
    "import pprint\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fcc3b5-4c4c-4dd0-8ffe-1b9692a85dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = '/media/arnau/PEN/TFG/train/'\n",
    "direc = '../data/'\n",
    "file = \"vizwiz_skill_typ_train.csv\"\n",
    "data = pd.read_csv(direc + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d71e0f2-c50d-4964-98c3-88ed34ef7e8f",
   "metadata": {},
   "source": [
    "Load images (these images are a combination of 2 VizWiz datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaa2be0-5adf-41a5-8fc9-4167f8b9a42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/all_imgs.json', 'r', encoding='UTF-8') as json_file:\n",
    "    all_imgs = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63b3536-56c2-4281-a41d-53095ac08c42",
   "metadata": {},
   "source": [
    "Get the info that says if the img is blurred or not from VizWiz assessing quality dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5526ef50-5587-4017-b86c-a63e715d3017",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json_qlty = '../data/'\n",
    "\n",
    "# Read assessing quality dataset \n",
    "with open(train_json_qlty + \"final.json\", encoding='UTF-8') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    data = data[\"train\"]  \n",
    "    \n",
    "data_size = len(data)\n",
    "print(f\"Dataset size: {data_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8024e5-1d89-47b7-85ae-660942e92aed",
   "metadata": {},
   "source": [
    "Create 2 subdatasets containing blurred and non blurred images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a11ae01-715c-4211-ae76-8e6e1a8e5694",
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_imgs = []\n",
    "non_blurred_imgs = []\n",
    "\n",
    "for i, img in enumerate(all_imgs):\n",
    "    img_info =  data[img]\n",
    "    imgs_flaws = img_info[\"flaws\"]\n",
    "    # if image is blurred\n",
    "    if img_info and imgs_flaws[1] == True:\n",
    "        blurred_imgs.append(img)\n",
    "    # if image is non-flawed\n",
    "    elif imgs_flaws[6] == True:\n",
    "        non_blurred_imgs.append(img)\n",
    "        \n",
    "non_blurred_imgs = non_blurred_imgs[: len(blurred_imgs)]\n",
    "print(f\"Number of non-blurred images {len(non_blurred_imgs)}\")\n",
    "print(f\"Number of blurred images {len(blurred_imgs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc06cf1b-7d31-4608-bedd-2df899767a16",
   "metadata": {},
   "source": [
    "Known issues:\n",
    "\n",
    "- *The images that are not blurred are the ones that have the \"NON flawed\" property*\n",
    "- *Some images are more blurred than others leaving the dataset unbalanced*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43dccfb-4ae0-40e2-a8eb-4fb0b5cecf65",
   "metadata": {},
   "source": [
    "### Validation & Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b72558-e22d-4796-8956-6fbdb21ca767",
   "metadata": {},
   "source": [
    "**NOTE:** The test set is extracted from the validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036c1b94-49e9-463c-b6ea-3be8f14144ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_json_qlty + \"final_val.json\", encoding='UTF-8') as json_file:\n",
    "    data_val = json.load(json_file)[\"val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8522ca24-2e6c-4897-b118-bdbdb69f4b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_blurred_imgs = []\n",
    "val_non_blurred_imgs = []\n",
    "size = int(0.1 * len(non_blurred_imgs))  # ~ 10%\n",
    "\n",
    "for img, img_info in data_val.items():\n",
    "    imgs_flaws = img_info[\"flaws\"]\n",
    "    # if image is blurred\n",
    "    if img_info and imgs_flaws[1] == True:\n",
    "        val_blurred_imgs.append(img)\n",
    "    # if image is non-flawed\n",
    "    elif imgs_flaws[6] == True:\n",
    "        val_non_blurred_imgs.append(img)\n",
    "        \n",
    "val_non_blurred_split = val_non_blurred_imgs[: size]\n",
    "val_blurred_split = val_blurred_imgs[: size]\n",
    "\n",
    "test_non_blurred_split = val_non_blurred_imgs[size : 2*size]\n",
    "test_blurred_split = val_blurred_imgs[size : 2*size]\n",
    "\n",
    "print(f\"Number of val non-blurred images: {len(val_non_blurred_split)}\")\n",
    "print(f\"Number of val blurred images: {len(val_blurred_split)}\")\n",
    "print(f\"\\nNumber of test non-blurred images: {len(test_non_blurred_split)}\")\n",
    "print(f\"Number of test blurred images: {len(test_blurred_split)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5ab369-f991-4fd1-bfe2-af0ce25f113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nbi = [(img, 0) for img in non_blurred_imgs]\n",
    "train_bi = [(img, 1) for img in blurred_imgs]\n",
    "val_nbi = [(img, 0) for img in val_non_blurred_split]\n",
    "val_bi = [(img, 1) for img in val_blurred_split]\n",
    "test_nbi = [(img, 0) for img in test_non_blurred_split]\n",
    "test_bi = [(img, 1) for img in test_blurred_split]\n",
    "\n",
    "# Train set\n",
    "vw_train_data = train_nbi + train_bi  \n",
    "# Validation set\n",
    "vw_val_data = val_nbi + val_bi\n",
    "# Test set\n",
    "vw_test_data = test_nbi + test_bi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7de0e79-68ba-4937-b249-b88d6a0e6d2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Blur dataset (Kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe45715-278c-43d7-8859-5e7a45626938",
   "metadata": {},
   "source": [
    "[Dataset](https://www.kaggle.com/datasets/kwentar/blur-dataset)\n",
    "\n",
    "3 categories\n",
    "\n",
    " - **S**: Sharp\n",
    " - **M**: Motion Blurred\n",
    " - **F**: Defocused Blurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa65a0c-5d56-4219-a99a-618f16f5d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895f0001-9161-4a73-84d8-72f7b01df568",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharp, defocused_blurred, motion_blurred = [], [], []\n",
    "types = [\"sharp\", \"defocused_blurred\", \"motion_blurred\"]\n",
    "\n",
    "for t in types:\n",
    "    dir_path = f'/media/arnau/PEN/TFG/blur_dataset/blur_dataset_scaled/{t}/'\n",
    "    for img_name in os.listdir(dir_path):\n",
    "        if t == \"sharp\":\n",
    "            sharp.append(dir_path + img_name)\n",
    "        elif t == \"defocused_blurred\":\n",
    "            defocused_blurred.append(dir_path + img_name)\n",
    "        elif t == \"motion_blurred\":\n",
    "            motion_blurred.append(dir_path + img_name)\n",
    "\n",
    "train_sharp = sharp[: int(0.8 * len(sharp))]\n",
    "train_defocused_blurred = defocused_blurred[: int(0.8 * len(defocused_blurred))]\n",
    "train_motion_blurred = motion_blurred[: int(0.8 * len(motion_blurred))]\n",
    "\n",
    "val_sharp = sharp[int(0.8 * len(sharp)) : int(0.8 * len(sharp)) + int(0.2 * len(sharp))]\n",
    "val_defocused_blurred = defocused_blurred[int(0.8 * len(defocused_blurred)) : int(0.8 * len(defocused_blurred)) + int(0.2 * len(defocused_blurred))]\n",
    "val_motion_blurred = motion_blurred[int(0.8 * len(motion_blurred)) : int(0.8 * len(motion_blurred)) + int(0.2 * len(motion_blurred))]\n",
    "\n",
    "# Training set\n",
    "bk_train = train_sharp + train_defocused_blurred + train_motion_blurred\n",
    "# Validation set\n",
    "bk_val = val_sharp + val_defocused_blurred + val_motion_blurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390e06fb-be0e-48c1-9cdd-0b1225102aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "dest_train = '/media/arnau/PEN/TFG/blur_dataset/blur_dataset_scaled/train/'\n",
    "dest_val = '/media/arnau/PEN/TFG/blur_dataset/blur_dataset_scaled/val/'\n",
    "\n",
    "for filename in bk_train:\n",
    "    if filename not in dest_train:\n",
    "        shutil.copy(filename, dest_train)\n",
    "    \n",
    "for filename in bk_val:\n",
    "    if filename not in dest_val:\n",
    "        shutil.copy(filename, dest_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91ca285-0944-4f1d-bc00-3aecb27e685e",
   "metadata": {},
   "source": [
    "# Join VizWiz + Blur Kaggle datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be02849-e04c-4457-9214-e2e29c464c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57f7db8-6fde-4fd7-bdf7-ee99c45a22db",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(2023)\n",
    "\n",
    "size_vw_train = size_bk_train = len(bk_train)   # 80% \n",
    "size_vw_val = size_bk_val = len(bk_val)   # 10% \n",
    "size_vw_test = len(bk_val) * 2   # 10%\n",
    "size_bk_test = 0 \n",
    "\n",
    "\n",
    "vw_vw_train_data_amp = random.choices(vw_train_data, k=size_bk_train)\n",
    "vw_vw_val_data_amp = random.choices(vw_val_data, k=size_bk_val)\n",
    "bk_val = random.choices(bk_val, k=size_bk_val)\n",
    "vw_vw_test_data_data = random.choices(vw_test_data, k=size_vw_test)\n",
    "\n",
    "# Blur dataset kagle + VizWiz dataset (train)\n",
    "bvw_vw_train_data = bk_train + vw_vw_train_data_amp\n",
    "# Blur dataset kagle + VizWiz dataset (val)\n",
    "bvw_vw_val_data = bk_val + vw_vw_val_data_amp\n",
    "# Vizwiz test data\n",
    "vw_test_data = vw_vw_test_data_data\n",
    "\n",
    "print(f\"Dataset size: {len(bvw_vw_train_data) + len(bvw_vw_val_data) + len(vw_test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09aa9092-dff7-4035-a08d-ebdc09e5bbc5",
   "metadata": {},
   "source": [
    "Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c10b934-1207-4d2f-ba0e-f69a12121253",
   "metadata": {},
   "outputs": [],
   "source": [
    "datam = {\"train\" : bvw_vw_train_data,\n",
    "        \"val\" : bvw_vw_val_data,\n",
    "           \"test\": vw_test_data}\n",
    "\n",
    "\n",
    "with open('../data/mixed_vwbk_dataset.json', 'w') as outfile:\n",
    "    json.dump(datam, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
